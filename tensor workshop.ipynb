{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тензоры\n",
    "Тензором размерности $d$ (или, чаще говорят, порядка $d$) называется $d$-мерная таблица ($d$-мерная матрица), составленная из элементов $a(i_1, ..., i_d)$. Иногда тензор размерности $d$ называется также $d$-тензором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_tensor(*shape):\n",
    "    return np.random.rand(*shape)\n",
    "\n",
    "def ones_tensor(*shape):\n",
    "    return np.ones(shape)\n",
    "\n",
    "def zeros_tensor(*shape):\n",
    "    return np.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.65165005 0.37709339]\n",
      "  [0.62949854 0.14544187]]\n",
      "\n",
      " [[0.69058601 0.26477611]\n",
      "  [0.44132633 0.15534393]]]\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(rand_tensor(2,2,2))\n",
    "print(ones_tensor(1,2,3))\n",
    "print(zeros_tensor(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Матрицы, ассоциированные с тензором\n",
    "\n",
    "Для трехмерного тензора $a(i, j, k)$ размера $n_1 \\times n_2 \\times n_3$ естественным образом определяются матрицы развертки $a_1$, $a_2$ и $a_3$ по каждому из трех измерений:\n",
    "$a_1[i; jk] = a_2[j; ik] = a_3[k; ij] = a[i, j, k]$.\n",
    "\n",
    "Матрицы $a_1$, $a_2$ и $a_3$ имеют соответственно размеры $n_1 \\times n_2 n_3$, $n_2 \\times n_1 n_3$ и $n_3 \\times n_1 n_2$.\n",
    "Точка с запятой используется, чтобы отделить строчные и столбцовые индексы\n",
    "матрицы. $jk$, $ik$ и $ij$ - это составные индексы.\n",
    "\n",
    "По определению, составной индекс $ij$ принимает столько значений, сколько имеется пар значений для $i$ и $j$. При изображении матриц в виде таблиц считается, что для составных индексов используется лексикографический порядок: в паре индексов $(i, j)$ сначала изменяется $j$, затем $i$. Если $i$ и $j$ принимают значения $1, 2, 3$ и\n",
    "$1, 2$ соответственно, то пары $(i, j)$ выстраиваются в последовательность $$(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2).$$\n",
    "Аналогичным образом определяется лексикографический порядок для составных индексов $ijk$, $ijkl$ и так далее.\n",
    "\n",
    "Матрицы $a(i_1 ... i_k; i_{k+1} ... i_d)$ называются стандартными ассоциированными матрицами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold_tensor(tensor, rows_indexes_number=0):\n",
    "    n = rows_indexes_number\n",
    "    rows = int(np.product(tensor.shape[:n]))\n",
    "    cols = int(np.product(tensor.shape[n:]))\n",
    "    return np.reshape(tensor, (rows, cols))\n",
    "\n",
    "def fold_matrix(matrix, shape):\n",
    "    return np.reshape(matrix, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1111 1112]\n",
      "   [1121 1122]]\n",
      "\n",
      "  [[1211 1212]\n",
      "   [1221 1222]]]\n",
      "\n",
      "\n",
      " [[[2111 2112]\n",
      "   [2121 2122]]\n",
      "\n",
      "  [[2211 2212]\n",
      "   [2221 2222]]]]\n"
     ]
    }
   ],
   "source": [
    "t = np.empty((2,2,2,2), dtype=int)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            for l in range(2):\n",
    "                t[i][j][k][l] = int(f'{i + 1}{j + 1}{k + 1}{l + 1}')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1111 1112 1121 1122 1211 1212 1221 1222 2111 2112 2121 2122 2211 2212\n",
      "  2221 2222]]\n"
     ]
    }
   ],
   "source": [
    "m0 = unfold_tensor(t)\n",
    "print(m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1111 1112 1121 1122 1211 1212 1221 1222]\n",
      " [2111 2112 2121 2122 2211 2212 2221 2222]]\n"
     ]
    }
   ],
   "source": [
    "m1 = unfold_tensor(t, 1)\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1111 1112 1121 1122]\n",
      " [1211 1212 1221 1222]\n",
      " [2111 2112 2121 2122]\n",
      " [2211 2212 2221 2222]]\n"
     ]
    }
   ],
   "source": [
    "m2 = unfold_tensor(t, 2)\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1111 1112]\n",
      " [1121 1122]\n",
      " [1211 1212]\n",
      " [1221 1222]\n",
      " [2111 2112]\n",
      " [2121 2122]\n",
      " [2211 2212]\n",
      " [2221 2222]]\n"
     ]
    }
   ],
   "source": [
    "m3 = unfold_tensor(t, 3)\n",
    "print(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(fold_matrix(m0, t.shape), t)\n",
    "assert np.array_equal(fold_matrix(m1, t.shape), t)\n",
    "assert np.array_equal(fold_matrix(m2, t.shape), t)\n",
    "assert np.array_equal(fold_matrix(m3, t.shape), t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Норма Фробениуса одна и та же для любой матрицы, ассоциированной с одним и тем же тензором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fro(matrix):\n",
    "    return la.norm(matrix, 'fro')\n",
    "\n",
    "def dist(m1, m2):\n",
    "    return fro(m1 - m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fro(m0) == fro(m1) == fro(m2) == fro(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранговые матричные разложения\n",
    "\n",
    "Пусть $A$ - произвольная матрица размера $m\\times n$ ранга $r$, тогда ранговое разложение имеет вид $A = UV$, где $U$ — матрица $m\\times r$ и $V$ — матрица $r\\times n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скелетное разложение\n",
    "Матрица $A = a(i, j)$ с элементами вида $a[i, j] = u(i)v(j)$ называется скелетоном.\n",
    "Представление матрицы в виде суммы скелетонов называется ее скелетным разложением или каноническим разложением. Сумма $r$ скелетонов определяется системами столбцов $u_1, ..., u_r$ и $v_1, ..., v_r$ и имеет вид $$A = \\sum_{\\alpha=1}^r u_\\alpha v_\\alpha^T = UV,$$\n",
    "где $$U = [u_1, ..., u_r], V = [v_1, ..., v_r]^T$$\n",
    "Минимально возможное число скелетонов называется рангом матрицы $a(i, j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_decomposition(matrix):\n",
    "    raise NotImplementedError('DO IT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сингулярное разложение (SVD)\n",
    "\n",
    "Пусть имеется скелетное разложение комплексной матрицы A, записанное в виде $$A = \\sum_{\\alpha = 1}^r = \\sigma_\\alpha u_\\alpha v_\\alpha^*,$$\n",
    "где $$\\sigma_1 \\ge \\sigma_2 \\ge ... \\ge \\sigma_r \\ge 0$$\n",
    "и каждая из систем столбцов $u_1, ..., u_r$ и $v_1, ..., v_r$ является ортонормированной при естественном скалярном произведении. Такое разложение называется сингулярным разложением матрицы $A$.\n",
    "\n",
    "Пусть $A_k$ получается из сингулярного разложения матрицы $A$ отбрасыванием скелетонов с номерами $\\alpha \\ge k + 1$. Тогда\n",
    "$$\\min_{rankB \\le k}||A - B||_2 = ||A - A_k||_2 = \\sigma_{k+1},$$\n",
    "$$\\min_{rankB \\le k}||A - B||_F = ||A - A_k||_F = \\sqrt{\\sum_{\\alpha \\ge k + 1}\\sigma_\\alpha^2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _svd(matrix, eps=1e-6):\n",
    "    u, s, v = la.svd(matrix, full_matrices=False)\n",
    "    id_ = s.size\n",
    "    for i, s_val in enumerate(s):\n",
    "        if s_val <= eps:\n",
    "            id_ = i\n",
    "            break\n",
    "    id_ = max(id_, 1)\n",
    "    return u[:,:id_], s[:id_], v[:id_,:]\n",
    "\n",
    "def svd_decomposition(matrix, eps=1e-6):\n",
    "    u, s, v = _svd(matrix, eps)\n",
    "    return u, np.diag(s) @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "(3,)\n",
      "(3, 4)\n",
      "[5.17842823 2.58487444 0.70873494]\n"
     ]
    }
   ],
   "source": [
    "m = [\n",
    "    [1, 0, 2, 0],\n",
    "    [0, 1, 0, 3],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 2, 3],\n",
    "]\n",
    "\n",
    "u, s, v = _svd(m)\n",
    "for i in (u, s, v):\n",
    "    print(i.shape)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9825620866736277e-15\n"
     ]
    }
   ],
   "source": [
    "u, v = svd_decomposition(m)\n",
    "print(dist(m, u @ v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(2, 4)\n",
      "0.7087349353283674\n",
      "0.7087349353283673\n"
     ]
    }
   ],
   "source": [
    "u, v = svd_decomposition(m, eps=s[-1])\n",
    "for i in (u, v):\n",
    "    print(i.shape)\n",
    "print(dist(m, u @ v))\n",
    "print(s[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "(1, 4)\n",
      "2.680276309338857\n",
      "2.680276309338856\n"
     ]
    }
   ],
   "source": [
    "u, v = svd_decomposition(m, eps=s[-2])\n",
    "for i in (u, v):\n",
    "    print(i.shape)\n",
    "print(dist(m, u @ v))\n",
    "print((s[-1]**2 + s[-2]**2)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложение в тензорный поезд\n",
    "\n",
    "$$T(n_1, n_2, ..., n_d) = G(n_1, r_1) G(r_1, n_2, r_2) G(r_2, n_3, r_3) ... G(r_{d-2}, n_{d-1}, r_{d-1}) G(r_{d-1}, n_d)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/tt_tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_cores(tensor, mtrx_decomposition_func):\n",
    "    \"\"\"\n",
    "    Decompose tensor of size (n1, n2, ..., nd) to\n",
    "    list of TT cores of sizes\n",
    "    [(n1, r1), (r1, n2, r2), (r2, n2, r3), ..., (rd, nd)]\n",
    "    \"\"\"\n",
    "    decomposition = []\n",
    "    \n",
    "    t = tensor\n",
    "    while True:\n",
    "        mtrx = unfold_tensor(t, 1)\n",
    "        u, v = mtrx_decomposition_func(mtrx)\n",
    "        decomposition.append(u)\n",
    "        \n",
    "        if t.ndim == 2:\n",
    "            decomposition.append(v)\n",
    "            break\n",
    "        \n",
    "        # Get next step tensor of size (r_i * n_{i+1}, n_{i+2}, ...)\n",
    "        r = v.shape[0]\n",
    "        n = t.shape[1]\n",
    "        t = fold_matrix(v, (r * n, *t.shape[2:]))\n",
    "    \n",
    "    for i in range(1, len(decomposition) - 1):\n",
    "        # Transform (r_{i-1} * n_i, r_i) matrix\n",
    "        # to (r_{i-1}, n_i, r_i) tensor\n",
    "        prev_r = decomposition[i - 1].shape[-1]\n",
    "        r = decomposition[i].shape[1]\n",
    "        n = decomposition[i].shape[0] // prev_r\n",
    "        u = fold_matrix(decomposition[i], (prev_r, n, r))\n",
    "        decomposition[i] = u\n",
    "\n",
    "    return decomposition\n",
    "\n",
    "\n",
    "def from_tt_cores(cores):\n",
    "    cores_iterator = iter(cores)\n",
    "    tensor = next(cores_iterator)\n",
    "    for core in cores_iterator:\n",
    "        # Dot product over rank indexes\n",
    "        # of tensor of size (n_1, ..., n_{i-1}, r_{i-1})\n",
    "        # and core of size (r_{i-1}, n_i, r_i)\n",
    "        # Result is a tensor of size (n_1, ..., n_{i-1}, n_i, r_i)\n",
    "        tensor = np.tensordot(tensor, core, axes=([-1], [0]))\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(1, 2, 1)\n",
      "(1, 2, 1)\n",
      "(1, 2, 1)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "t = ones_tensor(2,2,2,2,2)\n",
    "cores = tt_cores(t, svd_decomposition)\n",
    "for c in cores:\n",
    "    print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2, 2, 2)\n",
      "(2, 2, 2, 2, 2)\n",
      "1.9293619143415393e-15\n"
     ]
    }
   ],
   "source": [
    "restored_t = from_tt_cores(cores)\n",
    "print(t.shape)\n",
    "print(restored_t.shape)\n",
    "print(dist(unfold_tensor(t), unfold_tensor(restored_t)))\n",
    "# Check tensors are element-wise equal within a tolerance\n",
    "assert np.allclose(t, restored_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = ones_tensor(*(2,) * 15)\n",
    "cores = tt_cores(t, svd_decomposition)\n",
    "assert np.allclose(t, from_tt_cores(cores))\n",
    "print('1. Tensor with {} elements reduced to {} elements'.format(t.size, sum(c.size for c in cores)))\n",
    "\n",
    "t = np.array([math.sin(x) / x for x in np.arange(1.0, 2.0, 1 / (2**15))])\n",
    "t = t.reshape((2,) * 15)\n",
    "cores = tt_cores(t, svd_decomposition)\n",
    "assert np.allclose(t, from_tt_cores(cores))\n",
    "print('2. Tensor with {} elements reduced to {} elements'.format(t.size, sum(c.size for c in cores)))\n",
    "\n",
    "t = rand_tensor(*(2,) * 15)\n",
    "cores = tt_cores(t, svd_decomposition)\n",
    "assert np.allclose(t, from_tt_cores(cores))\n",
    "print('3. Tensor with {} elements reduced to {} elements'.format(t.size, sum(c.size for c in cores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]]\n",
      "2 [[[0.79444893 0.42348587]\n",
      "  [0.6841869  0.59169781]]\n",
      "\n",
      " [[0.60609944 0.98496639]\n",
      "  [0.04097922 0.25777322]]]\n",
      "3 [[[1.79444893 1.42348587]\n",
      "  [1.6841869  1.59169781]]\n",
      "\n",
      " [[1.60609944 1.98496639]\n",
      "  [1.04097922 1.25777322]]]\n",
      "new cores is [array([[-0.70710678, -0.74256333, -0.66977586],\n",
      "       [-0.70710678, -0.66977586,  0.74256333]])\n",
      " array([[[-0.70710678,  0.        ,  0.        ],\n",
      "        [-0.70710678,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        , -0.82243163,  0.09914922],\n",
      "        [ 0.        , -0.47972726, -0.09629651]],\n",
      "\n",
      "       [[ 0.        ,  0.15671499,  0.90383775],\n",
      "        [ 0.        , -0.26250407,  0.4049367 ]]])\n",
      " array([[ 2.        ,  2.        ],\n",
      "       [ 1.17538507,  1.21874956],\n",
      "       [-0.29456167,  0.28408083]])]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "def union_cores(a, b):\n",
    "    '''\n",
    "    create from cores (a1, n, a2) and (b1, n, b2) new core (a1 + b1, n, a2 + b2)\n",
    "    core a in upper left corner, b in bottom right. Other elements are zeroes\n",
    "    '''\n",
    "    part1 = np.concatenate((a, np.zeros(a.shape[:2] + (b.shape[2],))), axis = 2)\n",
    "    part2 = np.concatenate((np.zeros(b.shape[:2] + (a.shape[2],)), b), axis = 2)\n",
    "    return np.concatenate((part1, part2))\n",
    "\n",
    "\n",
    "def sum_tt(a, b):\n",
    "    '''\n",
    "    sum tensores in tt format.\n",
    "    return cores of (a + b) tensor\n",
    "    TODO:round this!\n",
    "    '''\n",
    "    new_cores = []\n",
    "    for i in range(len(a)):\n",
    "        if i == 0:\n",
    "            new_cores.append(np.concatenate((a[i], b[i]), axis = 1))\n",
    "        elif i == len(a) - 1:\n",
    "            new_cores.append(np.concatenate((a[i], b[i])))\n",
    "        else:\n",
    "            new_cores.append(union_cores(a[i], b[i]))\n",
    "    return np.array(new_cores)\n",
    "\n",
    "t0 = ones_tensor(2,2,2)\n",
    "t1 = rand_tensor(2,2,2)\n",
    "tc0 = tt_cores(t0, svd_decomposition)\n",
    "tc1 = tt_cores(t1, svd_decomposition)\n",
    "t2 = sum_tt(tc0, tc1)\n",
    "print(1, t0)\n",
    "print(2, t1)\n",
    "print(3, from_tt_cores(t2))\n",
    "print('new cores is', t2)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.41421356],\n",
      "       [-1.41421356]])\n",
      " array([[[-0.70710678],\n",
      "        [-0.70710678]]]) array([[2., 2.]])]\n",
      "[[[2. 2.]\n",
      "  [2. 2.]]\n",
      "\n",
      " [[2. 2.]\n",
      "  [2. 2.]]]\n"
     ]
    }
   ],
   "source": [
    "def mult_tt_by_number(a, k):\n",
    "    '''\n",
    "    return tt cores of tensor in tt format multiplied by k\n",
    "    probably you should multiply random core to prevent precision errors\n",
    "    '''\n",
    "    new_cores = np.copy(a)\n",
    "    new_cores[0] = new_cores[0] * k\n",
    "    return new_cores\n",
    "\n",
    "t = ones_tensor(2,2,2)\n",
    "tc = tt_cores(t, svd_decomposition)\n",
    "t2 = mult_tt_by_number(tc, 2)\n",
    "print(t2)\n",
    "print(from_tt_cores(t2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
